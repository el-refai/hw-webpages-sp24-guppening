<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>CS 184 Final Project: LE4GS - Language Embedded 4D Gaussian Splatting</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Abstract</a></li>
							<li><a href="#technical-approach">Technical Approach</a></li>
							<li><a href="#results">Results</a></li>
							<li><a href="#references">References</a></li>
							<li><a href="#contributions">Contributions</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<section class="wrapper style1 fullscreen fade-up">
					<div class="inner">
						<h1>CS 184 Final Project: LE4GS 
              <br />
              Language Embedded 4D Gaussian Splatting
            </h1>
            <h2>
              James DeLoye, Karim El-Refai, Andrew Wang, Jenny Nyugen
            </h2>
					</div>
				</section>
				<!-- Intro -->
					<section id="intro" class="wrapper style1-alt fullscreen fade-up">
						<div class="inner">
							<h1>Abstract</h1>
							<p>
                Quick synthesis of novel views in a 3D scene given a limited amount of
                views is a fast-growing research area in graphics and computer vision. A
                variety of approaches to learn the plenoptic function have been
                explored, including Neural Radiance Fields, Plenoxels, and recently, 3D
                Gaussian Splatting, a technique where a machine learning model fills a
                scene with millions of anisotropic 3D Gaussians and optimizes their
                shape, size, and color to approximate the scene as best as possible.
              </p>
              <p>
                Extensions to Gaussian splatting such as 4D Gaussian Splatting and
                Language-Embedded 3D Gaussian Splatting allow for quick rendering of
                novel views within a dynamic scene from obtained from videos (as opposed
                a static scene obtained from images) as well as identification/semantic
                encoding of objects in a scene, respectively.
              </p>
              <p>
                Our project aims to combine the two to add semantic encoding across time
                within the changing scene learned by Gaussian Splatting, allowing the
                creation of heatmaps and fast object tracking within scenes.
              </p>
							<!-- <ul class="actions">
								<li><a href="#one" class="button scrolly">Learn more</a></li>
							</ul> -->
						</div>
					</section>

				<!-- One -->
					<section id="technical-approach" class="wrapper style2 fade-up">
								<div class="inner">
									<h2>Technical Approach - Background</h2>
                  <h3>Gaussian Splatting</h3>
                  <p>
                    Gaussian splatting is a rendering technique that is can represent 3 dimensional scenes by "painting" with 3D gaussians. It has quickly gained in popularity due it its ability to render complex scenes without the high computational cost of NERFs or other 3D rendering techniques.
                    The first step in generating a splat is to gather data, typically a series of photos or a video of a single object or scene taken with a RGB camera and some sort of depth sensor, such as LIDAR.
                    With many perspectives of the same scene, the underlying depth and 3D structure of the scene can be inferred using structure from motion (SFM) algorithms. 
                    Below is an example of a point cloud generated from an SFM algorithm.
                  </p>
                  <div style="display: flex; justify-content: center;">
                  <figure>
                    <img src="images/coli-cloud.jpg" alt="A point cloud of the Coliseum generated from SFM algorithms" style="height: 300px;">
                    <figcaption style="text-align: center;">A point cloud of the Coliseum generated from SFM algorithms</figcaption>
                  </figure>
                  </div>
                  <p>
                    To each point in this cloud, a 3D gaussian, the extension of the 1D gaussian (bell curve/normal distribution) to 3 dimensions, is assigned. Each one of these gaussians has a center, determined by the corresponding point in a point cloud, and a covariance matrix, which determines the shape of the gaussian. Note that these gaussians are anisotropic, meaning that the axes are not necessarily axis-aligned. Finally, each gaussian also has a color and an opacity. The values of all these attributes are determined by a neural network which is trained to minimize the difference between the image generated by the rendered gaussians and the ground truth data. Since gaussians are infinitely differentiable, these optimal values can be found via gradient descent. Below is a scene with a bicycle rendered with Gaussian Splatting, and the same scene with fully opaque gaussians such that each can be clearly distinguished. Finally there is a "densification" step, which removes gaussians that are so transparent that they don't contribute to the image, or divides gaussians that are so big that there is a significant loss in detail.
                  </p>
                  <div style="display: flex; justify-content: center;">
                  <figure>
                    <img src="images/bicycle.png" alt="A bike rendered with gaussian splatting" style="padding-right:5px; height: 300px;"/>
                    <figcaption style="text-align: center;">A bike rendered with Gaussian Splatting</figcaption>
                  </figure>
                  <figure>
                    <img src="images/opaque.png" alt="A bike with fully opaque gaussians" style="height: 300px;"/>
                    <figcaption style="text-align: center;">The same bike Gaussian Splat with fully opaque gaussians </figcaption>
                  </figure>
                  </div>          
                  <div style="display: flex; justify-content: center;">          
                  <video width="80%" controls>
                    <source src="images/bicycle.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                  </div>
                  <div style="text-align: center;">The same bicycle dynamically rendered in 3D using Gaussian Splatting </div>
                  <br>
                  <h3>Dynamic and Language Embedded Splatting</h3>
									<p>
                    As Gaussian Splatting has gained in popularity, the original technique has been iterated upon and developed in a number of ways. One such way has been to extend the technique to dynamic scenes, essentially allowing for the rendering of 3D video. This has been accomplished in a number of ways ranging from moving the gaussians throughout the scene to track movement to simply extending the gaussians to a 4th dimension, and allowing them to vary over time. We focused on 
                  </p>
								</div>
					</section>

          <section class="wrapper style2-alt fade-up">
              <div class="inner">
                <h2>Technical Approach - Contributions</h2>
                <h3>Real-Time Dynamic and Language Embedded Gaussian Visualization</h3>
                <p>
                </p>
                <h3>Language Embedded 4D Gaussian Splatting</h3>
                <p>

                </p>
              </div>
          </section>

				<!-- Results -->
					<section id="results" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Results</h2>

							<h3>Final Presentation Video</h3>
							<iframe src="" onload='javascript:(function(o){o.style.height=o.contentWindow.document.body.scrollHeight+"px";}(this));' style="height:700px;width:100%;border:none;overflow:hidden;"></iframe>
						</div>
					</section>

          <section id="in-progress-work" class="wrapper style3-alt fade-up">
            <div class='inner'>
              <h2>
                In-Progress Work
              </h2>
            </div>
          </section>

				<!-- References -->
					<section id="references" class="wrapper style4 fade-up">
						<div class="inner">
							<h2>References</h2>
							<p>Shaders</p>
							<ul>
								<li><a href="https://github.com/sefinek24/Genshin-Impact-ReShade">Genshin-Impact-ReShade</a></li>
								<li>Kyprianidis, J. E., Kang, H., & Döllner, J. (2010). Anisotropic Kuwahara Filtering on the GPU. In W. Engel (Ed.), GPU Pro - Advanced Rendering Techniques. AK Peters, pp. 247–264.
								</li>
							</ul>
							
							<p>NeRF</p>
							<ul>
								<li><a href="https://github.com/nerfstudio-project/nerfstudio">NeRF Studio</a></li>
								<li><a href="https://godotengine.org/">GoDot</a></li>
							</ul>
						</div>
					</section>

					<section id="contributions" class="wrapper style4-alt fade-up">
						<div class="inner">
							<h2>Contributions</h2>
							<p>James</p>
							<ul>

							</ul>
							<p>Karim</p>
							<ul>

							</ul>
							<p>Andrew</p>
							<ul>

							</ul>
							<p>Jenny</p>
							<ul>

							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>