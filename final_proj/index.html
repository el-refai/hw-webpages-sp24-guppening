<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>CS 184 Final Project: LE4GS - Language Embedded 4D Gaussian Splatting</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Abstract</a></li>
							<li><a href="#technical-approach">Technical Approach</a></li>
							<li><a href="#results">Results</a></li>
							<li><a href="#references">References</a></li>
							<li><a href="#contributions">Contributions</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<section class="wrapper style1 fullscreen fade-up">
					<div class="inner">
						<h1>CS 184 Final Project: LE4GS 
              <br />
              Language Embedded 4D Gaussian Splatting
            </h1>
            <h2>
              James DeLoye, Karim El-Refai, Andrew Wang, Jenny Nyugen
            </h2>
					</div>
				</section>
				<!-- Intro -->
					<section id="intro" class="wrapper style1-alt fullscreen fade-up">
						<div class="inner">
							<h1>Abstract</h1>
							<p>
                Quick synthesis of novel views in a 3D scene given a limited amount of
                views is a fast-growing research area in graphics and computer vision. A
                variety of approaches to learn the plenoptic function have been
                explored, including Neural Radiance Fields, Plenoxels, and recently, 3D
                Gaussian Splatting, a technique where a machine learning model fills a
                scene with millions of anisotropic 3D Gaussians and optimizes their
                shape, size, and color to approximate the scene as best as possible.
              </p>
              <p>
                Extensions to Gaussian splatting such as 4D Gaussian Splatting and
                Language-Embedded 3D Gaussian Splatting allow for quick rendering of
                novel views within a dynamic scene from obtained from videos (as opposed
                a static scene obtained from images) as well as identification/semantic
                encoding of objects in a scene, respectively.
              </p>
              <p>
                Our project aims to combine the two to add semantic encoding across time
                within the changing scene learned by Gaussian Splatting, allowing the
                creation of heatmaps and fast object tracking within scenes.
              </p>
							<!-- <ul class="actions">
								<li><a href="#one" class="button scrolly">Learn more</a></li>
							</ul> -->
						</div>
					</section>

				<!-- One -->
					<section id="technical-approach" class="wrapper style2 fade-up">
								<div class="inner">
									<h2>Technical Approach - Background</h2>
                  <h3>Gaussian Splatting</h3>
                  <h3>Dynamic and Language Embedded Splatting</h3>
									<p></p>
								</div>
					</section>

          <section class="wrapper style2-alt fade-up">
              <div class="inner">
                <h2>Technical Approach - Contributions</h2>
                <h3>Real-Time Dynamic and Language-Embedded Gaussian Visualization</h3>
                <p>
                </p>
                <h3>Language Embedded 4D Gaussian Splatting</h3>
                <p>

                </p>
              </div>
          </section>

				<!-- Results -->
					<section id="results" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Results</h2>

							<h3>Final Presentation Video</h3>
							<iframe src="https://www.youtube.com/embed/3tgNSHy1Af4" onload='javascript:(function(o){o.style.height=o.contentWindow.document.body.scrollHeight+"px";}(this));' style="height:700px;width:100%;border:none;overflow:hidden;"></iframe>
						</div>
					</section>

          <section id="in-progress-work" class="wrapper style3-alt fade-up">
            <div class='inner'>
              <h2>
                In-Progress Work
              </h2>
              <h3>Semantic Object Querying on the Interactive Viewer</h3>
              <p>Since we do have </p>
              <h3>Multi-Level Language Querying</h3>
              <p></p>
              <h3>Getting Language-Embedded 4D Gaussian Splats to Work</h3>
              <p>Our current issues with presently trained model are that the language features at any given point are zero. This results in the blank rendering that was shown in video above in the  We believe this due to  
                this is </p>
              <h3>Training LE4GS on Photo-Realistic and Custom Data</h3>
              <p>Our approach is capable of working on photo-realistic scenes however most dynamic datasets collected in the real-world do not provide the ground truth camera poses. This means we much optimize these camera poses using Structure-from-Motion techniques such as COLMAP [1,2]. We are working through setting up COLMAP and have access to both iPhones 
                with LiDAR and Intel Realsense Depth cameras, meaning that we can capture both depth and RGB images. With these we're able to generate 
                custom dynamic scenes using real-world data. </p>
            </div>
          </section>

				<!-- References -->
					<section id="references" class="wrapper style4 fade-up">
						<div class="inner">
							<h2>References</h2>
							<p>Structure from Motion</p>
							<ul>
                <li>
                  [1], Schönberger, J. L., Zheng, E., Pollefeys, M., & Frahm, J.-M. (2016). Pixelwise View Selection for Unstructured Multi-View Stereo. In European Conference on Computer Vision (ECCV).
            </li>
              <li>
                [2], Schönberger, J. L., & Frahm, J.-M. (2016). Structure-from-Motion Revisited. In Conference on Computer Vision and Pattern Recognition (CVPR).
                </li>
								<li><a href="https://github.com/sefinek24/Genshin-Impact-ReShade">Genshin-Impact-ReShade</a></li>
								<li>Kyprianidis, J. E., Kang, H., & Döllner, J. (2010). Anisotropic Kuwahara Filtering on the GPU. In W. Engel (Ed.), GPU Pro - Advanced Rendering Techniques. AK Peters, pp. 247–264.
								</li>
							</ul>
							
							<p>NeRF</p>
							<ul>
								<li><a href="https://github.com/nerfstudio-project/nerfstudio">NeRF Studio</a></li>
								<li><a href="https://godotengine.org/">GoDot</a></li>
							</ul>
						</div>
					</section>

					<section id="contributions" class="wrapper style4-alt fade-up">
						<div class="inner">
							<h2>Contributions</h2>
							<p>James</p>
							<ul>
							</ul>
							<p>Karim</p>
							<ul>

							</ul>
							<p>Andrew</p>
							<ul>

							</ul>
							<p>Jenny</p>
							<ul>

							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
