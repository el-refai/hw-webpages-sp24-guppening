<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <style>
      body {
        background-color: #404040;
        background-color: white;
        padding: 100px;
        width: 1000px;
        margin: auto;
        text-align: left;
        font-weight: 300;
        font-family: "Open Sans", sans-serif;
        color: #121212;
        cursor: url(images/dwagon.png), default !important;
        cursor: url(images/dwagon.png), pointer !important;
      }
      h1,
      h2,
      h3,
      h4 {
        font-family: "Source Sans Pro", sans-serif;
      }
      kbd {
        color: #121212;
      }
      blockquote {
        color: #888;
        border: 2px solid #333;
        padding: 10px;
        background-color: #ccc;
      }

      table.custom-tbl {
        border: 1px solid;
      }

      table.custom-tbl th {
        border: 1px solid;
        background-color: rgb(99, 209, 209);
      }

      table.custom-tbl td {
        border: 1px solid;
        background-color: #f1e686a8;
      }

      /* The alert message box */
      .alert {
        padding: 20px;
        background-color: #f44336; /* Red */
        color: white;
        margin-bottom: 15px;
      }

      /* The close button */
      .closebtn {
        margin-left: 15px;
        color: white;
        font-weight: bold;
        float: right;
        font-size: 22px;
        line-height: 20px;
        cursor: pointer;
        transition: 0.3s;
      }

      /* When moving the mouse over the close button */
      .closebtn:hover {
        color: black;
      }
    </style>

    <title>CS 184 Homework Web Page</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <!-- Not using below due to lacking bold fontfaces -->
    <!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro|Source+Sans+Pro:400,700" rel="stylesheet"> -->
    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab|Roboto:300,400,500,700"
      rel="stylesheet"
    />

    <script>
      MathJax = {
        tex: {
          inlineMath: [
            ["$", "$"],
            ["\\(", "\\)"],
          ],
        },
      };
    </script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
    ></script>
  </head>

  <body style="padding-top: 50px">
    <h1 align="left">Language Embedded Dynamic Gaussian Splatting</h1>
    <h1 align="left">Final Project</h1>
    <h2 align="left">
      James Deloye, Karim El-Refai, Andrew Wang, Jenny Nguyen
    </h2>
    <h2 align="left">
      <a href="https://el-refai.github.io/the_guppening/milestone/index.html"
        >https://el-refai.github.io/the_guppening/milestone/index.html</a
      >
    </h2>

    <hr />
    <br />

    <div>
      <h2 align="center">Summary</h2>
      <p>
        Quick synthesis of novel views in a 3D scene given a limited amount of
        views is a fast-growing research area in graphics and computer vision. A
        variety of approaches to learn the plenoptic function have been
        explored, including Neural Radiance Fields, Plenoxels, and recently, 3D
        Gaussian Splatting, a technique where a machine learning model fills a
        scene with millions of anisotropic 3D Gaussians and optimizes their
        shape, size, and color to approximate the scene as best as possible.
      </p>
      <p>
        Extensions to Gaussian splatting such as 4D Gaussian Splatting and
        Language-Embedded 3D Gaussian Splatting allow for quick rendering of
        novel views within a dynamic scene from obtained from videos (as opposed
        a static scene obtained from images) as well as identification/semantic
        encoding of objects in a scene, respectively.
      </p>
      <p>
        Our project aims to combine the two to add semantic encoding across time
        within the changing scene learned by Gaussian Splatting, allowing the
        creation of heatmaps and fast object tracking within scenes.
      </p>
    </div>

    <hr />
    <br />

    <h3>Current Progress</h3>
    <div>
      <p>
        Our group spent the first week reading important papers describing the
        technologies used in the project, primarily those concerning 3D and 4D
        Gaussian splatting as well as Language-Embedded Gaussian Splatting.
      </p>
      <p>
        After familiarizing ourselves with the techniques and technologies used,
        the second week was spent familiarizing ourselves with the code in each
        of the two papers' repositories we aim to combine and setup to produce
        some example renders matching the quality described in the papers.
      </p>
      <p>
        However, getting these repos set up and working was much harder than
        expected. For both repositories, the provided instructions did not work.
        As a result, we spent several days working out dependencies and
        interactions between the packages and CUDA. The recommended CUDA version
        was not compatibile with their subpackages, and required a
        reconstruction of the proper CUDA and PyTorch versions to use to ensure
        compatibility. Eventually though, we got the dependencies worked out and
        were able to start using both repos to generate Gaussian Splats.
      </p>
      <p>
        To demonstrate 4D Gaussian splatting, our group used a dynamic scene
        containing bouncing balls from the DeNeRF dataset. To demonstrate 3D
        Language Gaussian Splatting, a video with changing camera positions in a
        static scene containing various objects on a sofa with color
        highlighting for objects in different classes was produced.
      </p>
      <p>
        We are currently on track to meet the project deadline based on the
        schedule we set out during the proposal. The coming weeks will involve
        adding dependencies (such as SAM, CLIP, DINO, and other models needed
        for natural language embedding), refactoring the model architecture to
        support features from both projects, and work on producing final
        renders.
      </p>
      <p>
        If we have time, we will also try to add an interactive visualization
        where you can "explore" the scene or query objects.
      </p>
    </div>

    <br />

    <h3>Video and Slide Deck</h3>
    <div align="center">
      <iframe
        width="560"
        height="315"
        src="https://www.youtube.com/embed/sGMagqGOsik?si=3fRaOLCZn4S2GCtc"
        title="YouTube video player"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerpolicy="strict-origin-when-cross-origin"
        allowfullscreen
      ></iframe>
    </div>

    <p>
      Slides are located at
      <a
        href="https://docs.google.com/presentation/d/17SEqLnP4aeZ3LolzHzASdQVUwtHwK8mZIX6sH54Taa4/edit#slide=id.g2d13474dfb7_1_22"
        >this link</a
      >
      or in the embed below.
    </p>
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTYUrdsmPXqlAu65i6DHEFTVSX9_FPOVCjOA3Kl0myVsZQmaW_mDlkPGh6HGbiFqqoRu6sa8kgLXhEB/embed?start=false&loop=false&delayms=5000" 
    frameborder="0" 
    width="960" 
    height="569" 
    allowfullscreen="true"
    mozallowfullscreen="true" 
    webkitallowfullscreen="true"></iframe>
    <br />

    <h3>Figures</h3>
    <h4>
      4D Gaussian Splatting Rendered Frames (Left: Actual, Right: Rendered)
    </h4>
    <div align="middle">
      <table style="width: 100%">
        <tr align="center">
          <td>
            <img
              src="images/4dg_stack_comparison_0.png"
              align="middle"
              style="width: 12vw"
            />
          </td>
          <td>
            <img
              src="images/4dg_stack_comparison_1.png"
              align="middle"
              style="width: 12vw"
            />
          </td>
          <td>
            <img
              src="images/4dg_stack_comparison_2.png"
              align="middle"
              style="width: 12vw"
            />
          </td>
          <td>
            <img
              src="images/4dg_stack_comparison_3.png"
              align="middle"
              style="width: 12vw"
            />
          </td>
        </tr>
      </table>
    </div>

    <br />

    

    <h4>Langsplat Rendered Gifs (Left: Actual, Right: Rendered)</h4>
    <div align="middle">
      <table style="width: 100%">
        <tr align="left">
          <td>
            <h5>L1 Features (Finest Grain, Subparts)</h5>
          </td>
        </tr>
        <tr align="center">
          <td>
            <img
              src="videos/langsplat_l1_gt.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
          <td>
            <img
              src="videos/langsplat_l1_render.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
        </tr>
        <tr align="left">
          <td>
            <h5>L2 Features (Medium Grain, Parts)</h5>
          </td>
        </tr>
        <tr align="center">
          <td>
            <img
              src="videos/langsplat_l2_gt.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
          <td>
            <img
              src="videos/langsplat_l2_render.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
        </tr>
        <tr align="left">
          <td>
            <h5>L3 Features (Coarsest Grain, Whole Objects)</h5>
          </td>
        </tr>
        <tr align="center">
          <td>
            <img
              src="videos/langsplat_l3_gt.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
          <td>
            <img
              src="videos/langsplat_l3_render.gif"
              align="middle"
              style="width: 20vw"
            />
          </td>
        </tr>
      </table>
    </div>

    <h3>Rendering to the Viewer Steps</h3>
    <ol>
      <li>Model learns dynamic scene using 4DGS / 3DLEGS</li>
      <li>Initialization
        <ul>
          <li>Initialize a socket to establish communication with SIBR viewer through which the model and viewer communicate</li>
          <li>Two-way communication initiated between model client and viewer when both are running</li>
        </ul>
      </li>
      <li>Rendering Loop
        <ul>
          <li>SIBR viewer sends camera parameters to model through established socket connection</li>
          <li>CUDA kernel renders a frame based on the parameters received through the socket and sends it back to the viewer</li>
        </ul>
      </li>
      <li>Viewer Display
        <ul>
          <li>User changes parameters to affect visualization through interactive panels in the viewer (timestamp, language features, etc)</li>
        </ul>
      </li>
    </ol>

    <h3>Interactive Viewer Visualizations</h3>
      <div style="text-align: center;">
        <h4>Bouncing Balls</h4>
        <video controls width="100%">
          <source src="videos/bouncingballs.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p>Toggling the timestamp in the GUI shows the balls bouncing, and the gaussian splats capture the nice shadows and squish of the balls.</p>
      </div>
      <div style="text-align: center;">
        <h4>Hell Warrior</h4>
        <video controls width="100%">
          <source src="videos/hellwarrior.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p>Using the keycaps "I", "J", "K", and "L" is how you would rotate the camera around to see the warrior in the SIBR viewer.</p>
      </div>
      <div style="text-align: center;">
        <h4>Jumping Jacks</h4>
        <video controls width="100%">
          <source src="videos/jumpingjacks.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p>Using the keycaps "W", "A", "S", and "D" is how you would move the camera up, down, and to the sides in the viewer.</p>
      </div>

    <h3>References</h3>
    <ol>
      <li>Zeyu Yang, Hongye Yang, Zijie Pan, Li Zhang (2024). Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting</li>
      <li>Minghan Qin, Wanhua Li, Jiawei Zhou, Haoqian Wang, Hanspeter Pfister, Tsinghua University, Harvard University (2024). LangSplat: 3D Language Gaussian Splatting.</li>
      <li>Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng (2020). NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.</li>
      <li>Justin Kerr, Chung Min Kim, Ken Goldberg, Angjoo Kanazawa, Matthew Tancik (2023). LERF: Language Embedded Radiance Fields.</li>
      <li>Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, George Drettakis (2023). 3D Gaussian Splatting for Real-Time Radiance Field Rendering</li>
      <li>Yuanxing Duan, Fangyin Wei, Qiyu Dai, Yuhang He, Wenzheng Chen, Baoquan Chen (2024). 4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes.</li>
      <li>Justin Yu, Kush Hari, Kishore Srinivas, Karim El-Refai, Adam Rashid, Chung Min Kim, Justin Kerr, Richard Cheng, Ashwin Balakrishna, Thomas Kollar, Ken Goldberg (2024). Incrementally Building Room-Scale Language-Embedded Gaussian Splats (LEGS) with a Mobile Robot.</li>
      <li>Jonathon Luiten, Georgios kopanas, Bastian Leibe, Deva Ramanan (2023). Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis.</li>
    </ol>

    <h3>Contributions</h3>
    <div>
      <h4>Karim</h4>
      <ul>
        <li>Brainstormed Theory Behind Combining Models: played a key role in conceptualizing how to integrate the 4D Gaussian Splatting (4DGS) and Language-Embedded 3D Gaussian Splatting (LEGS) models. 
          He provided the relevant research papers and synthesized the necessary theoretical framework to guide the team's efforts.</li>
        <li>Research and Paper Review: conducted thorough research on various papers related to dynamic scene representation, object tracking, and semantic querying. He provided valuable insights from 
          these papers to inform the team's approach and decision-making process.</li>
        <li>Model Training: took charge of training various models, including those for dynamic scenes like bouncing balls, hellwarrior, hook, and five more.</li>
        <li>Setting Up Compute Devices: Karim was responsible for configuring and setting up the necessary compute devices required for training and running the models ("was stuck in CUDA hell"). His efforts ensured smooth execution 
          of computational tasks throughout the project.</li>
        <li>Investigation of SIBR Viewer: Karim explored the SIBR viewer, a crucial component for visualizing and interacting with the rendered scenes. He assessed its capabilities and compatibility with 
          the team's objectives, providing insights for its integration into the project workflow.</li>
      </ul>
    </div>
    <div>
      <h4>James</h4>
      <ul>
        <li>Resolution of Environment Issues: James played a crucial role in troubleshooting and resolving environment setup issues encountered at the beginning of the 4D Gaussian Splatting (4DGS) implementation. 
          His efforts ensured a smooth transition into the development phase of the project.</li>
        <li>Integration of Models: spearheaded the integration of the 4DGS and LEGS models, combining their functionalities to create a unified framework for dynamic scene representation.</li>
        <li>Theory Development: contributed to the theoretical underpinnings of the project, particularly in refining the conceptual framework behind the combined model approach.</li>
        <li>Website Content Creation: wrote explanatory content for the project website of the project's goals, methodologies, and outcomes to a wider audience.</li>
      </ul>
    </div>
    <div>
      <h4>Andrew</h4>
      <ul>
        <li>Presentation and Website Development: led the creation of the project presentation and webpage for the milestone. He meticulously organized and presented the project's progress, findings, and future 
          directions in a compelling and coherent manner.</li>
        <li>Interactive Viewer Adaptation: adapted the interactive viewer to support 4DGS, enabling real-time visualization and manipulation of rendered scenes.</li>
        <li>Visualization Creation:  created visualizations to showcase the capabilities of the interactive viewer and the rendered scenes.</li>
      </ul>
    </div>
    <div>
      <h4>Jenny</h4>
      <ul>
        <li>Presentation Development: contributed to the development of the project presentation.</li>
        <li>Website Content Creation: collaborated on writing content for the project webpage.</li>
      </ul>
    </div>

    
  </body>
</html>